# 🔍 RAG_APP — Retrieval-Augmented Generation Web App

**RAG_APP** is a Streamlit-powered application that allows users to upload PDF documents, embed their content into a vector database using **OpenAI embeddings**, and perform semantic search with natural language queries. The answers are generated contextually using **LangChain** and **GPT models**.

This project demonstrates a complete **RAG (Retrieval-Augmented Generation)** pipeline using modern tools like **Pinecone**, **OpenAI**, and **LangChain**.

---

## 📌 Table of Contents

- [Features](#features)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Setup & Installation](#setup--installation)
- [Environment Variables](#environment-variables)
- [Usage](#usage)
- [Example Workflow](#example-workflow)
- [Troubleshooting](#troubleshooting)
- [License](#license)
- [Author](#author)

---

## ✅ Features

- 📤 Upload and parse PDF files
- 🔠 Text chunking and cleaning
- 🧠 OpenAI-powered embeddings
- 📦 Store and retrieve vectors using Pinecone
- 💬 Chat-based query answering using LangChain
- 🎯 Simple UI with Streamlit

---

## 🧱 Tech Stack

| Layer      | Tech Used             |
|------------|------------------------|
| Frontend   | Streamlit              |
| Backend    | Python, LangChain      |
| Embeddings | OpenAI `text-embedding-ada-002` |
| Vector DB  | Pinecone               |
| File Parsing | PyPDF2              |
| Env Config | python-dotenv          |

---

## 🏗️ Architecture

```
User (query)
   ↓
Streamlit frontend
   ↓
LangChain
   ↓
Retriever (Pinecone Vector DB)
   ↓
Embedding Generator (OpenAI)
   ↓
Document Chunks (from PDF)
   ↓
Answer generated by GPT
```

---

## ⚙️ Setup & Installation

### 1. Clone the Repository

```bash
git clone https://github.com/devSRAG/RAG_APP.git
cd RAG_APP
```

### 2. (Optional but Recommended) Create a Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Required Packages

```bash
pip install -r requirements.txt
```

---

## 🔐 Environment Variables

Create a `.env` file in the root directory with the following variables:

```
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=your_pinecone_index_name
```

> ❗ *Never share your API keys publicly. Do not commit `.env` to Git.*

---

## ▶️ Usage

To run the Streamlit app:

```bash
streamlit run main.py
```

The app will open in your browser at:  
📍 `http://localhost:xxxx`

---

## 🧪 Example Workflow

1. **Upload a PDF**  
   Choose any document with readable text.

2. **Indexing**  
   The file gets split into chunks, embedded using OpenAI, and stored in Pinecone.

3. **Ask a Question**  
   Type a question like:  
   `"What is the conclusion of this document?"`

4. **Get Answer**  
   The app finds relevant document chunks and asks GPT to summarize/answer.

---

## 🛠️ Troubleshooting

| Issue | Solution |
|-------|----------|
| App crashes on PDF upload | Ensure the PDF is not encrypted or image-based only |
| `KeyError: OPENAI_API_KEY` | Check if `.env` is set up and variables are named correctly |
| Pinecone error | Ensure the index name exists and your environment is correct |
| "Streamlit not found" | Run `pip install streamlit` |

---

## 📄 License

This project is licensed under the **MIT License**.  
Feel free to use, modify, and distribute with credit.

---

## 👨‍💻 Author

Built by [@devSRAG](https://github.com/devSRAG)  
✨ Contributions, issues, and feedback are welcome!

---

## 🌟 Show Your Support

If you find this project helpful:

⭐ Star the repo  
🔁 Share it with friends  
🛠️ Fork and build your own custom version
